### 网络爬虫

Web crawler： 网络爬虫  
定义：

- 网络爬虫模拟人类使用浏览器浏览、操作页面的行为，对互联网的站点进行操作

- 网络爬虫获取到一个页面后，会分析出页面里的所有 URI,沿着这些 URI 路径递归的遍历所有页面，因此被称为爬虫

### 对待网络爬虫的两种态度

#### 欢迎常光临

这是搜索公司希望的情况

- SEO, 搜索引擎优化
  - 合法的优化： sitemap, title, keywords, https 等
  - 非法的优化： 利用 PageRank 算法漏洞

#### 拒绝访问

比如，购票服务

- 为了对抗网络爬虫而生的图形验证码

### 网络爬虫如何抓取数据？

- 模拟浏览器渲染引擎，需要对 Javascript 文件分析执行、发起 Ajax 请求等

- 爬虫爬取数据的速度 VS 互联网生成信息的速度

  - 爬虫执行速度快，许多爬虫可以并发执行
  - 互联网生成信息的速度远大于爬取速度

- 优先爬取更重要的页面（往往采用广度优先爬取）

### 爬虫常见的请求头部

- User-Agent: 识别是哪类爬虫
- From: 提供爬虫机器人管理者的邮箱地址
- Accept: 告知服务器爬虫对哪些资源类型感性取
- Referer: 相当于包含了当前请求的页面 URI

### robots.txt : 告知爬虫哪些内容不应爬取

- Robots exclusion protocol

- robots.txt 文件内容

  - User-agent: 允许哪些机器人
  - Disallow: 禁止访问特定目录
  - Crawl-delay: 访问间隔秒数
  - Allow: 抵消 Disallow 指令
  - Sitemap: 指出站点地图的 URI
